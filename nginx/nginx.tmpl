worker_processes  {{ .WorkerProcesses }};
daemon off;

error_log stderr {{ .LogLevel }};
pid {{ .WorkingDir }}/nginx.pid;

events {
    # Accept connections as fast as possible.
    multi_accept on;
    # Includes both proxy and client connections.
    # So e.g. 4096 = 2048 persistent client connections to backends per worker.
    worker_connections {{ .WorkerConnections }};
    # Use most optimal non-blocking selector on linux.
    # Should be selected by default on linux, we just make it explicit here.
    use epoll;
}

http {
    default_type text/html;

    # If a large number of server names are defined, or unusually long server names are defined,
    # tuning the server_names_hash_max_size and server_names_hash_bucket_size directives at the http
    # level may become necessary.
    {{ if gt .ServerNamesHashBucketSize 0 }}server_names_hash_bucket_size {{ .ServerNamesHashBucketSize }};{{ end }}
    {{ if gt .ServerNamesHashMaxSize 0 }}server_names_hash_max_size {{ .ServerNamesHashMaxSize }};{{ end }}

    # Keep alive time for client connections. Don't limit by number of requests.
    keepalive_timeout {{ .KeepaliveSeconds }}s;
    keepalive_requests 2147483647;

    # Optimize for latency over throughput for persistent connections.
    tcp_nodelay on;

    # Disable nginx version leakage to external clients.
    server_tokens off;

    # Obtain client IP from frontend's X-Forward-For header
{{ range .TrustedFrontends }}    set_real_ip_from {{ . }};
{{ end }}
    real_ip_header X-Forwarded-For;
    real_ip_recursive on;

    # Put all data into the working directory.
    access_log             off;
    client_body_temp_path  {{ .WorkingDir }}/tmp_client_body 1 2;
    proxy_temp_path        {{ .WorkingDir }}/tmp_proxy 1 2;
    fastcgi_temp_path      {{ .WorkingDir }}/tmp_fastcgi 1 2;
    uwsgi_temp_path        {{ .WorkingDir }}/tmp_uwsgi 1 2;
    scgi_temp_path         {{ .WorkingDir }}/tmp_scgi 1 2;

    # Configure proxying
    # Enable keepalive to backend.
    proxy_http_version 1.1;
    proxy_set_header Connection "";

    # Add headers for proxy information.
    map $http_x_forwarded_proto $frontend_scheme {
        default $http_x_forwarded_proto;
        '' $scheme;
    }
    map $http_x_forwarded_port $frontend_port {
        default $http_x_forwarded_port;
        '' $server_port;
    }
    proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;
    proxy_set_header X-Forwarded-Host $host:$frontend_port;
    proxy_set_header X-Forwarded-Proto $frontend_scheme;
    proxy_set_header X-Original-URI $request_uri;
    proxy_set_header X-Real-IP $remote_addr;

    # Timeout faster than the default 60s on initial connect.
    proxy_connect_timeout 10s;

    # Close proxy connections after backend keepalive time.
    proxy_read_timeout {{ .BackendKeepaliveSeconds }}s;
    proxy_send_timeout {{ .BackendKeepaliveSeconds }}s;

    # Disable buffering, as we'll be interacting with ELBs with http listeners, which we assume will
    # quickly consume and generate responses and requests.
    # This should be enabled if nginx will directly serve traffic externally to unknown clients.
    proxy_buffering off;

    # Configure ingresses
    {{ $port := .IngressPort }}
    {{ $keepalive := .BackendKeepalives }}
    {{ range $entry := .Entries }}
    # Start entry
    #{{ $entry.Name }}
{{- range $upstream := $entry.Upstreams }}
    upstream {{ $upstream.ID }} {
        server {{ $upstream.Server }};
        keepalive {{ $keepalive }};
    }
{{ end }}
    server {
        listen {{ $port }};
        server_name {{ $entry.ServerName }};
        {{- range $location := $entry.Locations }}

        location {{ if $location.Path }}{{ $location.Path }}{{ end }} {
            # Strip location path when proxying.
            proxy_pass http://{{ $location.UpstreamID }}/;

            # Allow localhost for debugging
            allow 127.0.0.1;

            # Restrict clients
            {{ range $location.Allow }}allow {{ . }};
            {{ end }}
            deny all;
        }
        {{- end }}
    }
    # End entry
    {{ end }}

    # End ingresses

    # Default backend
    server {
        listen {{ .IngressPort }} default_server;
        location / {
            return 404;
        }
    }

    # Status port. This should be firewalled to only allow internal access.
    server {
        listen {{ .HealthPort }} default_server reuseport;

        location /health {
            access_log off;
            return 200;
        }

        location /status {
            access_log off;
            stub_status;
        }

        location / {
            return 404;
        }
    }
}
